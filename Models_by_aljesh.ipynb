{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "566c2a73-e3ee-4ae3-9671-b36b291c9328",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent\n",
    "Regressors are fitted by stochastic gradient descent under convex loss functions, such as SVMs. Each sample at a time, the gradient of the loss is determined, and the model is updated along the way using a schedule of decreasing strength, or learning rate. The regularizer, which uses either the squared euclidean, L2, absolute, L1, or elastic net, is a penalty imposed to the loss function that reduces model parameters towards the zero vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67f30577-014d-4736-8ffe-cac96b509b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3654437418418539"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "import numpy as np\n",
    "rng = np.random.RandomState(0)\n",
    "y=rng.randn(10)\n",
    "x=rng.randn(10,5)\n",
    "z=rng.randn(10,5)\n",
    "model1 = SGDRegressor(loss=\"squared_error\",penalty=\"l2\", max_iter=1000)\n",
    "# Model1 uses squred error for the loss and squared euclidean for regularization\n",
    "model1.fit(x,y)\n",
    "model1.predict(z)\n",
    "model1.score(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d202aa98-17a4-411d-8d2d-4622e9a433ff",
   "metadata": {},
   "source": [
    "## Random Forest Regressor\n",
    "A random forest is a meta estimator that employs averaging to increase the predictive accuracy and control over fitting while fitting several decision tree regressors on different subsamples of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0504bfaa-3f7f-44d6-b17a-7b2ae02442e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7492562611963237"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model2 = RandomForestRegressor(bootstrap=True,max_depth=2,random_state=0)\n",
    "model2.fit(x,y)\n",
    "model2.predict(z)\n",
    "model2.score(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e805952-e65a-4181-b9b1-1a2b2b123f30",
   "metadata": {},
   "source": [
    "## Bagging Regressor\n",
    "An ensemble meta estimator known as a bagging regressor fits base regressors independently on random subsets of the original dataset, then aggregates each individual estimate to get the final prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61426e92-8216-4f53-8696-5d810ea6ed27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49471733804305396"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.svm import SVR\n",
    "model3 = BaggingRegressor(estimator=SVR(),n_estimators=10,random_state=0)\n",
    "model3.fit(x,y)\n",
    "model3.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3107700-42a1-4540-a1ce-f34eeb0af8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
